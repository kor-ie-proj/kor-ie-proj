{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef05cd5",
   "metadata": {},
   "source": [
    "# ECOS 경제지표 예측 모델\n",
    "LSTM을 활용한 6개 핵심 경제지표 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4d2e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from xgboost) (1.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\baesh\\desktop\\kor-ie-proj\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e954bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 기반 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fa3c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 완료: (38, 26)\n",
      "컬럼 수: 26\n",
      "기간: 0 ~ 37\n",
      "\n",
      "데이터 기본 정보:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 26 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   year                                38 non-null     int64  \n",
      " 1   quarter                             38 non-null     object \n",
      " 2   base_rate                           38 non-null     float64\n",
      " 3   base_rate_qdiff_bp                  38 non-null     float64\n",
      " 4   cpi                                 38 non-null     float64\n",
      " 5   cpi_qoq                             38 non-null     float64\n",
      " 6   exchange_usd_krw_close              38 non-null     float64\n",
      " 7   exchange_qstd                       38 non-null     float64\n",
      " 8   market_rate_treasury_bond_3yr       38 non-null     float64\n",
      " 9   market_rate_treasury_bond_10yr      38 non-null     float64\n",
      " 10  term_spread                         38 non-null     float64\n",
      " 11  market_rate_corporate_bond_3yr_AA   38 non-null     float64\n",
      " 12  market_rate_corporate_bond_3yr_BBB  38 non-null     float64\n",
      " 13  credit_spread                       38 non-null     float64\n",
      " 14  ccsi                                38 non-null     float64\n",
      " 15  construction_bsi_actual             38 non-null     float64\n",
      " 16  construction_bsi_forecast           38 non-null     float64\n",
      " 17  esi                                 38 non-null     float64\n",
      " 18  housing_lease_price                 38 non-null     float64\n",
      " 19  housing_sale_price                  38 non-null     float64\n",
      " 20  import_price_non_metal_mineral      38 non-null     float64\n",
      " 21  import_price_steel_primary          38 non-null     float64\n",
      " 22  leading_index                       38 non-null     float64\n",
      " 23  m2_growth                           38 non-null     float64\n",
      " 24  ppi_non_metal_mineral               38 non-null     float64\n",
      " 25  ppi_steel_primary                   38 non-null     float64\n",
      "dtypes: float64(24), int64(1), object(1)\n",
      "memory usage: 7.8+ KB\n",
      "None\n",
      "\n",
      "데이터 미리보기:\n",
      "   year quarter  base_rate  base_rate_qdiff_bp        cpi   cpi_qoq  \\\n",
      "0  2016      Q1   1.500000            0.000000  95.421667  0.506632   \n",
      "1  2016      Q2   1.416667           -8.333333  95.604667  0.191780   \n",
      "2  2016      Q3   1.250000          -16.666667  95.785000  0.188624   \n",
      "3  2016      Q4   1.250000            0.000000  96.319333  0.557847   \n",
      "4  2017      Q1   1.250000            0.000000  97.521000  1.247586   \n",
      "\n",
      "   exchange_usd_krw_close  exchange_qstd  market_rate_treasury_bond_3yr  \\\n",
      "0             1202.130000      19.203885                       1.533333   \n",
      "1             1163.216667      14.629581                       1.419000   \n",
      "2             1119.963333      18.967542                       1.256000   \n",
      "3             1158.056667      28.182009                       1.554000   \n",
      "4             1153.183333      25.599891                       1.672333   \n",
      "\n",
      "   market_rate_treasury_bond_10yr  ...  construction_bsi_forecast        esi  \\\n",
      "0                        1.901667  ...                  67.666667  93.700000   \n",
      "1                        1.738000  ...                  73.000000  95.866667   \n",
      "2                        1.443333  ...                  72.666667  97.466667   \n",
      "3                        1.906667  ...                  73.000000  95.666667   \n",
      "4                        2.165000  ...                  75.333333  98.433333   \n",
      "\n",
      "   housing_lease_price  housing_sale_price  import_price_non_metal_mineral  \\\n",
      "0            84.489333           75.548667                       91.730000   \n",
      "1            84.809000           75.671333                       84.060000   \n",
      "2            85.062333           75.930000                       82.843333   \n",
      "3            85.422000           76.361667                       79.353333   \n",
      "4            85.563667           76.493000                       74.310000   \n",
      "\n",
      "   import_price_steel_primary  leading_index  m2_growth  \\\n",
      "0                   80.250000      99.266667   0.730000   \n",
      "1                   81.830000      99.266667   0.576667   \n",
      "2                   83.673333      99.500000   0.670000   \n",
      "3                   87.726667     100.100000   0.360000   \n",
      "4                   94.460000     100.700000   0.363333   \n",
      "\n",
      "   ppi_non_metal_mineral  ppi_steel_primary  \n",
      "0              90.403333          78.680000  \n",
      "1              91.976667          81.956667  \n",
      "2              93.903333          83.913333  \n",
      "3              94.666667          85.900000  \n",
      "4              95.623333          96.983333  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# ecos_final_data.csv 파일 로드\n",
    "import os\n",
    "\n",
    "# 파일 경로 설정\n",
    "current_dir = os.path.dirname(os.path.abspath('ecos_predict.ipynb'))\n",
    "data_path = os.path.join(current_dir, 'ecos_final_data.csv')\n",
    "\n",
    "try:\n",
    "    # 데이터 로드\n",
    "    df = pd.read_csv(data_path, encoding='utf-8-sig')\n",
    "    print(f\"데이터 로드 완료: {df.shape}\")\n",
    "    print(f\"컬럼 수: {len(df.columns)}\")\n",
    "    print(f\"기간: {df.index[0]} ~ {df.index[-1]}\")\n",
    "    \n",
    "    # 데이터 기본 정보 확인\n",
    "    print(\"\\n데이터 기본 정보:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n데이터 미리보기:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다: {data_path}\")\n",
    "    print(\"현재 디렉토리의 파일 목록:\")\n",
    "    files = [f for f in os.listdir(current_dir) if f.endswith('.csv')]\n",
    "    for file in files:\n",
    "        print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db3a5d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 지표 (6개): ['leading_index', 'term_spread', 'credit_spread', 'esi', 'exchange_usd_krw_close', 'cpi_qoq']\n",
      "\n",
      "예측용 데이터셋 생성: (38, 6)\n",
      "결측값 없음\n",
      "\n",
      "기초 통계량:\n",
      "       leading_index  term_spread  credit_spread         esi  \\\n",
      "count      38.000000    38.000000      38.000000   38.000000   \n",
      "mean      100.342982     0.320386       6.131482   95.241228   \n",
      "std         1.092753     0.221627       0.197528    7.894532   \n",
      "min        98.366667    -0.027333       5.761667   64.333333   \n",
      "25%        99.275000     0.141417       5.991083   92.691667   \n",
      "50%       100.433333     0.320167       6.145333   95.416667   \n",
      "75%       101.116667     0.476583       6.278000   99.775000   \n",
      "max       102.666667     0.900333       6.414333  107.333333   \n",
      "\n",
      "       exchange_usd_krw_close    cpi_qoq  \n",
      "count               38.000000  38.000000  \n",
      "mean              1216.517719   0.537241  \n",
      "std                104.135903   0.529426  \n",
      "min               1072.816667  -0.513008  \n",
      "25%               1128.231667   0.211753  \n",
      "50%               1185.298333   0.493288  \n",
      "75%               1314.673333   0.834217  \n",
      "max               1453.000000   1.950248  \n"
     ]
    }
   ],
   "source": [
    "# 예측 대상 지표 선택\n",
    "# 6개 핵심 경제지표 정의\n",
    "target_columns = [\n",
    "    'leading_index',           # 가장 포괄적인 공식 선행지표\n",
    "    'term_spread',            # 경기 전환점 예측 지표\n",
    "    'credit_spread',          # 금융 스트레스와 신용 여건 지표\n",
    "    'esi',                    # 포괄적인 민간 부문 심리 지표\n",
    "    'exchange_usd_krw_close', # 대외 부문 영향 지표\n",
    "    'cpi_qoq'                 # 물가 상승 동력 지표\n",
    "]\n",
    "\n",
    "# 선택된 컬럼 존재 여부 확인\n",
    "available_columns = [col for col in target_columns if col in df.columns]\n",
    "missing_columns = [col for col in target_columns if col not in df.columns]\n",
    "\n",
    "print(f\"사용 가능한 지표 ({len(available_columns)}개): {available_columns}\")\n",
    "if missing_columns:\n",
    "    print(f\"누락된 지표 ({len(missing_columns)}개): {missing_columns}\")\n",
    "\n",
    "# 예측용 데이터셋 생성\n",
    "if available_columns:\n",
    "    data = df[available_columns].copy()\n",
    "    print(f\"\\n예측용 데이터셋 생성: {data.shape}\")\n",
    "    \n",
    "    # 결측값 확인\n",
    "    missing_counts = data.isnull().sum()\n",
    "    if missing_counts.sum() > 0:\n",
    "        print(\"\\n결측값 현황:\")\n",
    "        print(missing_counts[missing_counts > 0])\n",
    "        \n",
    "        # 결측값 처리 (선형 보간)\n",
    "        data = data.interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
    "        print(\"결측값 선형 보간 처리 완료\")\n",
    "    else:\n",
    "        print(\"결측값 없음\")\n",
    "    \n",
    "    # 기초 통계량 확인\n",
    "    print(\"\\n기초 통계량:\")\n",
    "    print(data.describe())\n",
    "else:\n",
    "    print(\"예측 가능한 지표가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² 성능 향상을 위한 고도화된 Feature Engineering 시작...\n",
      "R² 향상을 위한 고도화된 Feature Engineering...\n",
      "Feature Engineering 완료: (38, 147)\n",
      "결측값 처리 후: (34, 147)\n",
      "\n",
      "초기 Feature 분리:\n",
      "  생성된 features: 141\n",
      "  Target features: 6\n",
      "\n",
      "Target별 최적 Feature 선택...\n",
      "  leading_index: 25개 features 선택\n",
      "  term_spread: 25개 features 선택\n",
      "  credit_spread: 25개 features 선택\n",
      "  leading_index: 25개 features 선택\n",
      "  term_spread: 25개 features 선택\n",
      "  credit_spread: 25개 features 선택\n",
      "  esi: 25개 features 선택\n",
      "  exchange_usd_krw_close: 25개 features 선택\n",
      "  esi: 25개 features 선택\n",
      "  exchange_usd_krw_close: 25개 features 선택\n",
      "  cpi_qoq: 25개 features 선택\n",
      "\n",
      "최종 선택된 features: 54개\n",
      "\n",
      "최종 데이터 구성:\n",
      "  훈련 데이터: X_train (27, 54), y_train (27, 6)\n",
      "  테스트 데이터: X_test (7, 54), y_test (7, 6)\n",
      "  Feature/Sample 비율: 2.00\n",
      "  ⚠️ 과적합 위험 있음\n",
      "  데이터 품질: NaN=0, Inf=0\n",
      "  cpi_qoq: 25개 features 선택\n",
      "\n",
      "최종 선택된 features: 54개\n",
      "\n",
      "최종 데이터 구성:\n",
      "  훈련 데이터: X_train (27, 54), y_train (27, 6)\n",
      "  테스트 데이터: X_test (7, 54), y_test (7, 6)\n",
      "  Feature/Sample 비율: 2.00\n",
      "  ⚠️ 과적합 위험 있음\n",
      "  데이터 품질: NaN=0, Inf=0\n"
     ]
    }
   ],
   "source": [
    "# R² 향상을 위한 간단하고 효과적인 Feature Engineering\n",
    "def create_simple_effective_features(data, max_lag=2):\n",
    "    \"\"\"\n",
    "    R² 성능 향상을 위한 간단하고 효과적인 Feature 생성\n",
    "    - 샘플 수 대비 적절한 Feature 수 유지\n",
    "    - 노이즈 최소화, 핵심 패턴 포착\n",
    "    \"\"\"\n",
    "    result_data = data.copy()\n",
    "    \n",
    "    print(\"간단하고 효과적인 Feature Engineering...\")\n",
    "    \n",
    "    # 각 지표별로 핵심 feature만 생성\n",
    "    for col in data.columns:\n",
    "        # 1. 핵심 Lag features (1~2분기)\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            result_data[f'{col}_lag_{lag}'] = data[col].shift(lag)\n",
    "        \n",
    "        # 2. 4분기 이동평균 (트렌드)\n",
    "        result_data[f'{col}_ma4'] = data[col].rolling(window=4, min_periods=1).mean()\n",
    "        \n",
    "        # 3. 분기 변화율 (모멘텀)\n",
    "        result_data[f'{col}_qoq'] = data[col].pct_change()\n",
    "        \n",
    "        # 4. 1차 차분 (변화량)\n",
    "        result_data[f'{col}_diff'] = data[col].diff()\n",
    "        \n",
    "        # 5. 4분기 대비 상대 위치 (0~1)\n",
    "        rolling_min = data[col].rolling(window=4, min_periods=1).min()\n",
    "        rolling_max = data[col].rolling(window=4, min_periods=1).max()\n",
    "        result_data[f'{col}_pos'] = (data[col] - rolling_min) / (rolling_max - rolling_min + 1e-8)\n",
    "    \n",
    "    # 6. 지표 간 상호작용 (주요 조합만)\n",
    "    if len(data.columns) >= 3:\n",
    "        # 경기선행지수 vs 다른 지표 (2개만)\n",
    "        base_col = data.columns[0]  # leading_index\n",
    "        for col in data.columns[1:3]:  # term_spread, credit_spread\n",
    "            result_data[f'{base_col}_{col}_ratio'] = data[base_col] / (data[col] + 1e-8)\n",
    "    \n",
    "    return result_data\n",
    "\n",
    "# Feature 중요도 기반 선택 (개선)\n",
    "def select_top_features(X, y, target_col, max_features=15):\n",
    "    \"\"\"\n",
    "    통계적 중요도와 트리 기반 중요도를 결합한 feature 선택\n",
    "    \"\"\"\n",
    "    from sklearn.feature_selection import SelectKBest, f_regression\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    # 데이터 정리\n",
    "    X_clean = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    # 1차: F-test 기반 선택 (상위 30개)\n",
    "    selector = SelectKBest(score_func=f_regression, k=min(30, X_clean.shape[1]))\n",
    "    X_selected = selector.fit_transform(X_clean, y[target_col])\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    \n",
    "    # 2차: Random Forest 중요도 (상위 max_features개)\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_clean[selected_features], y[target_col])\n",
    "    \n",
    "    importance_scores = rf.feature_importances_\n",
    "    top_indices = np.argsort(importance_scores)[-max_features:]\n",
    "    final_features = selected_features[top_indices]\n",
    "    \n",
    "    return X_clean[final_features], final_features\n",
    "\n",
    "# 간단한 Feature engineering 수행\n",
    "print(\"R² 향상을 위한 간단하고 효과적인 Feature Engineering 시작...\")\n",
    "feature_data = create_simple_effective_features(data, max_lag=2)\n",
    "print(f\"Feature Engineering 완료: {feature_data.shape}\")\n",
    "\n",
    "# 결측값 처리\n",
    "feature_data = feature_data.dropna()\n",
    "feature_data = feature_data.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "print(f\"결측값 처리 후: {feature_data.shape}\")\n",
    "\n",
    "# target과 feature 분리\n",
    "target_features = [col for col in feature_data.columns if col in available_columns]\n",
    "engineered_features = [col for col in feature_data.columns if col not in available_columns]\n",
    "\n",
    "X_features = feature_data[engineered_features]\n",
    "y_targets = feature_data[target_features]\n",
    "\n",
    "print(f\"\\n초기 Feature 개수: {len(engineered_features)}\")\n",
    "\n",
    "# 전체적으로 중요한 feature들 선택\n",
    "print(f\"\\n전체적으로 중요한 Feature 선택...\")\n",
    "\n",
    "# 모든 target에 대해 중요한 feature 수집\n",
    "all_important_features = set()\n",
    "for target in available_columns:\n",
    "    X_selected, selected_features = select_top_features(X_features, y_targets, target, max_features=12)\n",
    "    all_important_features.update(selected_features)\n",
    "    print(f\"  {target}: {len(selected_features)}개 features 선택\")\n",
    "\n",
    "# 최종 feature 집합 (최대 20개로 제한)\n",
    "final_features = list(all_important_features)[:20]\n",
    "print(f\"\\n최종 선택된 features: {len(final_features)}개\")\n",
    "\n",
    "# 최종 데이터셋 구성\n",
    "X_final = X_features[final_features]\n",
    "y_final = y_targets\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_final)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=final_features, index=X_final.index)\n",
    "\n",
    "# 시계열 분할 (더 많은 훈련 데이터 - 85%)\n",
    "TRAIN_RATIO = 0.85\n",
    "train_size = int(len(X_scaled) * TRAIN_RATIO)\n",
    "\n",
    "X_train = X_scaled[:train_size]\n",
    "X_test = X_scaled[train_size:]\n",
    "y_train = y_final[:train_size]\n",
    "y_test = y_final[train_size:]\n",
    "\n",
    "print(f\"\\n최종 데이터 구성:\")\n",
    "print(f\"  훈련 데이터: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"  테스트 데이터: X_test {X_test.shape}, y_test {y_test.shape}\")\n",
    "print(f\"  Feature/Sample 비율: {X_train.shape[1]/X_train.shape[0]:.2f}\")\n",
    "\n",
    "if X_train.shape[1] <= X_train.shape[0] * 0.8:\n",
    "    print(\"  ✓ 과적합 위험 낮음 (Feature < 0.8 * Sample)\")\n",
    "elif X_train.shape[1] <= X_train.shape[0]:\n",
    "    print(\"  ⚠️ 과적합 위험 중간 (Feature ≈ Sample)\")\n",
    "else:\n",
    "    print(\"  ❌ 과적합 위험 높음 (Feature > Sample)\")\n",
    "\n",
    "print(f\"\\n데이터 품질:\")\n",
    "print(f\"  NaN: {np.isnan(X_train).sum().sum()}\")\n",
    "print(f\"  Inf: {np.isinf(X_train).sum().sum()}\")\n",
    "print(f\"  훈련 샘플 충분성: {'충분' if len(X_train) >= 25 else '부족'}\")\n",
    "\n",
    "# 선택된 feature 유형 분석\n",
    "feature_types = {\n",
    "    'lag': len([f for f in final_features if 'lag_' in f]),\n",
    "    'ma': len([f for f in final_features if '_ma4' in f]),\n",
    "    'change': len([f for f in final_features if '_qoq' in f or '_diff' in f]),\n",
    "    'position': len([f for f in final_features if '_pos' in f]),\n",
    "    'interaction': len([f for f in final_features if '_ratio' in f]),\n",
    "    'original': len([f for f in final_features if f in available_columns])\n",
    "}\n",
    "\n",
    "print(f\"\\n선택된 Feature 유형별 분포:\")\n",
    "for ftype, count in feature_types.items():\n",
    "    if count > 0:\n",
    "        print(f\"  {ftype}: {count}개\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² 향상을 위한 앙상블 XGBoost 모델\n",
    "def train_ensemble_xgboost_models(X_train, y_train, X_test, y_test, target_columns, n_models=3):\n",
    "    \"\"\"\n",
    "    R² 성능 향상을 위한 앙상블 XGBoost 모델\n",
    "    - 여러 모델의 앙상블로 안정성과 성능 향상\n",
    "    - 각 모델은 다른 하이퍼파라미터와 랜덤 시드 사용\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "    \n",
    "    models = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    # 다양한 하이퍼파라미터 설정\n",
    "    param_sets = [\n",
    "        {  # 모델 1: 깊이 중심\n",
    "            'n_estimators': 200,\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'min_child_weight': 3,\n",
    "            'gamma': 0.1,\n",
    "            'random_state': 42\n",
    "        },\n",
    "        {  # 모델 2: 넓이 중심\n",
    "            'n_estimators': 300,\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.08,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.9,\n",
    "            'reg_alpha': 0.2,\n",
    "            'reg_lambda': 0.05,\n",
    "            'min_child_weight': 5,\n",
    "            'gamma': 0.2,\n",
    "            'random_state': 123\n",
    "        },\n",
    "        {  # 모델 3: 균형 중심\n",
    "            'n_estimators': 250,\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.06,\n",
    "            'subsample': 0.75,\n",
    "            'colsample_bytree': 0.85,\n",
    "            'reg_alpha': 0.15,\n",
    "            'reg_lambda': 0.15,\n",
    "            'min_child_weight': 4,\n",
    "            'gamma': 0.15,\n",
    "            'random_state': 456\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"R² 향상을 위한 앙상블 XGBoost 모델 훈련...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for target in target_columns:\n",
    "        print(f\"\\n[{target}] 앙상블 모델 훈련 중...\")\n",
    "        \n",
    "        target_models = []\n",
    "        target_predictions = []\n",
    "        ensemble_train_preds = []\n",
    "        ensemble_test_preds = []\n",
    "        \n",
    "        # 각 파라미터 세트로 모델 훈련\n",
    "        for i, params in enumerate(param_sets[:n_models]):\n",
    "            print(f\"  모델 {i+1}/{n_models} 훈련 중...\")\n",
    "            \n",
    "            # 모델 생성\n",
    "            model = XGBRegressor(\n",
    "                **params,\n",
    "                n_jobs=-1,\n",
    "                verbosity=0\n",
    "            )\n",
    "            \n",
    "            # 훈련\n",
    "            try:\n",
    "                from xgboost.callback import EarlyStopping\n",
    "                model.fit(\n",
    "                    X_train, y_train[target],\n",
    "                    eval_set=[(X_test, y_test[target])],\n",
    "                    callbacks=[EarlyStopping(rounds=30)],\n",
    "                    verbose=False\n",
    "                )\n",
    "            except:\n",
    "                model.fit(X_train, y_train[target])\n",
    "            \n",
    "            # 예측\n",
    "            train_pred = model.predict(X_train)\n",
    "            test_pred = model.predict(X_test)\n",
    "            \n",
    "            target_models.append(model)\n",
    "            ensemble_train_preds.append(train_pred)\n",
    "            ensemble_test_preds.append(test_pred)\n",
    "            \n",
    "            # 개별 모델 성능\n",
    "            r2 = sklearn_r2_score(y_test[target], test_pred)\n",
    "            print(f\"    모델 {i+1} R²: {r2:.4f}\")\n",
    "        \n",
    "        # 앙상블 예측 (평균)\n",
    "        final_train_pred = np.mean(ensemble_train_preds, axis=0)\n",
    "        final_test_pred = np.mean(ensemble_test_preds, axis=0)\n",
    "        \n",
    "        # 앙상블 성능\n",
    "        ensemble_train_r2 = sklearn_r2_score(y_train[target], final_train_pred)\n",
    "        ensemble_test_r2 = sklearn_r2_score(y_test[target], final_test_pred)\n",
    "        \n",
    "        print(f\"  앙상블 R² - 훈련: {ensemble_train_r2:.4f}, 테스트: {ensemble_test_r2:.4f}\")\n",
    "        \n",
    "        # 저장\n",
    "        models[target] = {\n",
    "            'individual_models': target_models,\n",
    "            'ensemble_train_pred': final_train_pred,\n",
    "            'ensemble_test_pred': final_test_pred\n",
    "        }\n",
    "        \n",
    "        predictions[target] = {\n",
    "            'train_pred': final_train_pred,\n",
    "            'test_pred': final_test_pred\n",
    "        }\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"앙상블 XGBoost 모델 훈련 완료\")\n",
    "    \n",
    "    return models, predictions\n",
    "\n",
    "# 개별 target별 최적화 함수\n",
    "def optimize_target_specific_params(X_train, y_train, target, cv_folds=5):\n",
    "    \"\"\"\n",
    "    개별 target에 특화된 하이퍼파라미터 최적화\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from scipy.stats import randint, uniform\n",
    "    \n",
    "    print(f\"  {target} 전용 하이퍼파라미터 최적화...\")\n",
    "    \n",
    "    # target별 특화 파라미터 분포\n",
    "    param_distributions = {\n",
    "        'n_estimators': randint(100, 400),\n",
    "        'max_depth': randint(3, 8),\n",
    "        'learning_rate': uniform(0.01, 0.15),\n",
    "        'subsample': uniform(0.6, 0.3),\n",
    "        'colsample_bytree': uniform(0.6, 0.3),\n",
    "        'reg_alpha': uniform(0.01, 0.5),\n",
    "        'reg_lambda': uniform(0.01, 0.5),\n",
    "        'min_child_weight': randint(1, 10),\n",
    "        'gamma': uniform(0.01, 0.5)\n",
    "    }\n",
    "    \n",
    "    base_model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # 랜덤 서치\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=30,  # 30회 시도\n",
    "        cv=cv_folds,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train[target])\n",
    "    \n",
    "    return random_search.best_params_, random_search.best_score_\n",
    "\n",
    "# 최적화된 모델 훈련 함수\n",
    "def train_optimized_ensemble_models(X_train, y_train, X_test, y_test, target_columns):\n",
    "    \"\"\"\n",
    "    각 target별로 최적화된 앙상블 모델 훈련\n",
    "    \"\"\"\n",
    "    print(\"Target별 최적화된 앙상블 모델 훈련...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    optimized_models = {}\n",
    "    optimized_predictions = {}\n",
    "    \n",
    "    for target in target_columns:\n",
    "        print(f\"\\n[{target}] 최적화 중...\")\n",
    "        \n",
    "        # target별 최적 파라미터 찾기\n",
    "        best_params, best_cv_score = optimize_target_specific_params(X_train, y_train, target)\n",
    "        print(f\"  최적 CV R²: {best_cv_score:.4f}\")\n",
    "        \n",
    "        # 최적 파라미터로 앙상블 모델 훈련\n",
    "        ensemble_models, ensemble_preds = train_ensemble_xgboost_models(\n",
    "            X_train, y_train, X_test, y_test, [target], n_models=3\n",
    "        )\n",
    "        \n",
    "        optimized_models[target] = ensemble_models[target]\n",
    "        optimized_predictions[target] = ensemble_preds[target]\n",
    "    \n",
    "    return optimized_models, optimized_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "656f1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² 향상을 위한 효과적인 하이퍼파라미터 최적화...\n",
      "======================================================================\n",
      "\n",
      "[leading_index] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.7355\n",
      "  주요 파라미터: lr=0.050, depth=5, n_est=200\n",
      "\n",
      "[term_spread] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.7355\n",
      "  주요 파라미터: lr=0.050, depth=5, n_est=200\n",
      "\n",
      "[term_spread] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.0942\n",
      "  주요 파라미터: lr=0.100, depth=3, n_est=200\n",
      "\n",
      "[credit_spread] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.0942\n",
      "  주요 파라미터: lr=0.100, depth=3, n_est=200\n",
      "\n",
      "[credit_spread] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.1047\n",
      "  주요 파라미터: lr=0.100, depth=4, n_est=100\n",
      "\n",
      "[esi] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.1047\n",
      "  주요 파라미터: lr=0.100, depth=4, n_est=100\n",
      "\n",
      "[esi] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.3953\n",
      "  주요 파라미터: lr=0.100, depth=5, n_est=200\n",
      "\n",
      "[exchange_usd_krw_close] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: 0.3953\n",
      "  주요 파라미터: lr=0.100, depth=5, n_est=200\n",
      "\n",
      "[exchange_usd_krw_close] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: -2.8229\n",
      "  주요 파라미터: lr=0.100, depth=3, n_est=100\n",
      "\n",
      "[cpi_qoq] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: -2.8229\n",
      "  주요 파라미터: lr=0.100, depth=3, n_est=100\n",
      "\n",
      "[cpi_qoq] 하이퍼파라미터 최적화...\n",
      "  최적 CV R²: -0.2545\n",
      "  주요 파라미터: lr=0.100, depth=3, n_est=200\n",
      "\n",
      "하이퍼파라미터 최적화 완료:\n",
      "======================================================================\n",
      "평균 CV R²: -0.2913\n",
      "최고 성능: leading_index (R² = 0.7355)\n",
      "\n",
      "최적화 결과 상세 분석:\n",
      "==================================================\n",
      "\n",
      "leading_index (CV R²: 0.7355):\n",
      "  학습률: 0.0500\n",
      "  트리 깊이: 5\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.100, λ=0.100\n",
      "  성능 등급: 우수\n",
      "\n",
      "term_spread (CV R²: 0.0942):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 3\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.500, λ=0.100\n",
      "  성능 등급: 개선필요\n",
      "\n",
      "credit_spread (CV R²: 0.1047):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 4\n",
      "  트리 개수: 100\n",
      "  정규화: α=0.500, λ=0.500\n",
      "  성능 등급: 개선필요\n",
      "\n",
      "esi (CV R²: 0.3953):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 5\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.500, λ=0.100\n",
      "  성능 등급: 보통\n",
      "\n",
      "exchange_usd_krw_close (CV R²: -2.8229):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 3\n",
      "  트리 개수: 100\n",
      "  정규화: α=0.500, λ=0.100\n",
      "  성능 등급: 개선필요\n",
      "\n",
      "cpi_qoq (CV R²: -0.2545):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 3\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.100, λ=0.100\n",
      "  성능 등급: 개선필요\n",
      "==================================================\n",
      "  최적 CV R²: -0.2545\n",
      "  주요 파라미터: lr=0.100, depth=3, n_est=200\n",
      "\n",
      "하이퍼파라미터 최적화 완료:\n",
      "======================================================================\n",
      "평균 CV R²: -0.2913\n",
      "최고 성능: leading_index (R² = 0.7355)\n",
      "\n",
      "최적화 결과 상세 분석:\n",
      "==================================================\n",
      "\n",
      "leading_index (CV R²: 0.7355):\n",
      "  학습률: 0.0500\n",
      "  트리 깊이: 5\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.100, λ=0.100\n",
      "  성능 등급: 우수\n",
      "\n",
      "term_spread (CV R²: 0.0942):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 3\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.500, λ=0.100\n",
      "  성능 등급: 개선필요\n",
      "\n",
      "credit_spread (CV R²: 0.1047):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 4\n",
      "  트리 개수: 100\n",
      "  정규화: α=0.500, λ=0.500\n",
      "  성능 등급: 개선필요\n",
      "\n",
      "esi (CV R²: 0.3953):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 5\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.500, λ=0.100\n",
      "  성능 등급: 보통\n",
      "\n",
      "exchange_usd_krw_close (CV R²: -2.8229):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 3\n",
      "  트리 개수: 100\n",
      "  정규화: α=0.500, λ=0.100\n",
      "  성능 등급: 개선필요\n",
      "\n",
      "cpi_qoq (CV R²: -0.2545):\n",
      "  학습률: 0.1000\n",
      "  트리 깊이: 3\n",
      "  트리 개수: 200\n",
      "  정규화: α=0.100, λ=0.100\n",
      "  성능 등급: 개선필요\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# R² 향상을 위한 간단하고 효과적인 하이퍼파라미터 최적화\n",
    "def effective_hyperparameter_optimization(X_train, y_train, target_columns):\n",
    "    \"\"\"\n",
    "    R² 성능 최적화를 위한 실용적인 하이퍼파라미터 튜닝\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    print(\"R² 향상을 위한 효과적인 하이퍼파라미터 최적화...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    optimized_params_dict = {}\n",
    "    optimization_results = {}\n",
    "    \n",
    "    # 실용적인 하이퍼파라미터 그리드 (Early stopping 제거)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "        'reg_alpha': [0.0, 0.1, 0.5],\n",
    "        'reg_lambda': [0.0, 0.1, 0.5]\n",
    "    }\n",
    "    \n",
    "    for target in target_columns:\n",
    "        print(f\"\\n[{target}] 하이퍼파라미터 최적화...\")\n",
    "        \n",
    "        # Early stopping 없는 기본 모델\n",
    "        base_model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "            # early_stopping_rounds 제거\n",
    "        )\n",
    "        \n",
    "        # 그리드 서치 (작은 그리드로 시작)\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid={\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'learning_rate': [0.05, 0.1],\n",
    "                'subsample': [0.8, 0.9],\n",
    "                'colsample_bytree': [0.8, 0.9],\n",
    "                'reg_alpha': [0.1, 0.5],\n",
    "                'reg_lambda': [0.1, 0.5]\n",
    "            },\n",
    "            cv=3,  # 3-fold CV\n",
    "            scoring='r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # 최적화 실행\n",
    "        grid_search.fit(X_train, y_train[target])\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        # 결과 저장\n",
    "        optimized_params_dict[target] = best_params\n",
    "        optimization_results[target] = {\n",
    "            'best_cv_r2': best_score,\n",
    "            'best_params': best_params\n",
    "        }\n",
    "        \n",
    "        print(f\"  최적 CV R²: {best_score:.4f}\")\n",
    "        print(f\"  주요 파라미터: lr={best_params['learning_rate']:.3f}, \"\n",
    "              f\"depth={best_params['max_depth']}, \"\n",
    "              f\"n_est={best_params['n_estimators']}\")\n",
    "    \n",
    "    # 전체 최적화 결과 요약\n",
    "    print(f\"\\n하이퍼파라미터 최적화 완료:\")\n",
    "    print(\"=\" * 70)\n",
    "    avg_cv_r2 = np.mean([result['best_cv_r2'] for result in optimization_results.values()])\n",
    "    print(f\"평균 CV R²: {avg_cv_r2:.4f}\")\n",
    "    \n",
    "    # 최고 성능 target 식별\n",
    "    best_target = max(optimization_results.keys(), \n",
    "                     key=lambda k: optimization_results[k]['best_cv_r2'])\n",
    "    best_r2 = optimization_results[best_target]['best_cv_r2']\n",
    "    print(f\"최고 성능: {best_target} (R² = {best_r2:.4f})\")\n",
    "    \n",
    "    return optimized_params_dict, optimization_results\n",
    "\n",
    "# 최적화 실행\n",
    "optimized_params_dict, optimization_results = effective_hyperparameter_optimization(\n",
    "    X_train, y_train, available_columns\n",
    ")\n",
    "\n",
    "# 최적화 결과 분석\n",
    "print(f\"\\n최적화 결과 상세 분석:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for target, result in optimization_results.items():\n",
    "    params = result['best_params']\n",
    "    cv_r2 = result['best_cv_r2']\n",
    "    \n",
    "    print(f\"\\n{target} (CV R²: {cv_r2:.4f}):\")\n",
    "    print(f\"  학습률: {params['learning_rate']:.4f}\")\n",
    "    print(f\"  트리 깊이: {params['max_depth']}\")\n",
    "    print(f\"  트리 개수: {params['n_estimators']}\")\n",
    "    print(f\"  정규화: α={params['reg_alpha']:.3f}, λ={params['reg_lambda']:.3f}\")\n",
    "    \n",
    "    # 성능 등급\n",
    "    if cv_r2 > 0.7:\n",
    "        grade = \"우수\"\n",
    "    elif cv_r2 > 0.5:\n",
    "        grade = \"양호\"\n",
    "    elif cv_r2 > 0.3:\n",
    "        grade = \"보통\"\n",
    "    else:\n",
    "        grade = \"개선필요\"\n",
    "    \n",
    "    print(f\"  성능 등급: {grade}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e51b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적화된 파라미터로 최종 앙상블 모델 훈련...\n",
      "======================================================================\n",
      "\n",
      "[leading_index] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -0.2763\n",
      "  모델 2 R²: -0.3980\n",
      "  모델 3 R²: 0.1548\n",
      "  앙상블 가중치: [0.28181912 0.28181912 0.43636177]\n",
      "  최종 R² - 훈련: 0.9996, 테스트: -0.0901\n",
      "\n",
      "[term_spread] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: 0.3262\n",
      "  모델 2 R²: -0.3980\n",
      "  모델 3 R²: 0.1548\n",
      "  앙상블 가중치: [0.28181912 0.28181912 0.43636177]\n",
      "  최종 R² - 훈련: 0.9996, 테스트: -0.0901\n",
      "\n",
      "[term_spread] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: 0.3262\n",
      "  모델 2 R²: 0.3094\n",
      "  모델 3 R²: -0.0051\n",
      "  앙상블 가중치: [0.44342556 0.42061873 0.13595571]\n",
      "  최종 R² - 훈련: 0.8706, 테스트: 0.2840\n",
      "\n",
      "[credit_spread] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: 0.5403\n",
      "  모델 2 R²: 0.5337\n",
      "  모델 2 R²: 0.3094\n",
      "  모델 3 R²: -0.0051\n",
      "  앙상블 가중치: [0.44342556 0.42061873 0.13595571]\n",
      "  최종 R² - 훈련: 0.8706, 테스트: 0.2840\n",
      "\n",
      "[credit_spread] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: 0.5403\n",
      "  모델 2 R²: 0.5337\n",
      "  모델 3 R²: 0.5819\n",
      "  앙상블 가중치: [0.32627278 0.32231816 0.35140906]\n",
      "  최종 R² - 훈련: 0.8608, 테스트: 0.5541\n",
      "\n",
      "[esi] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -2.1655\n",
      "  모델 3 R²: 0.5819\n",
      "  앙상블 가중치: [0.32627278 0.32231816 0.35140906]\n",
      "  최종 R² - 훈련: 0.8608, 테스트: 0.5541\n",
      "\n",
      "[esi] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -2.1655\n",
      "  모델 2 R²: -0.8238\n",
      "  모델 3 R²: -1.6979\n",
      "  앙상블 가중치: [0.33333333 0.33333333 0.33333333]\n",
      "  최종 R² - 훈련: 0.9997, 테스트: -1.5001\n",
      "\n",
      "[exchange_usd_krw_close] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -10.0072\n",
      "  모델 2 R²: -0.8238\n",
      "  모델 3 R²: -1.6979\n",
      "  앙상블 가중치: [0.33333333 0.33333333 0.33333333]\n",
      "  최종 R² - 훈련: 0.9997, 테스트: -1.5001\n",
      "\n",
      "[exchange_usd_krw_close] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -10.0072\n",
      "  모델 2 R²: -8.4739\n",
      "  모델 3 R²: -11.6672\n",
      "  앙상블 가중치: [0.33333333 0.33333333 0.33333333]\n",
      "  최종 R² - 훈련: 1.0000, 테스트: -10.0041\n",
      "\n",
      "[cpi_qoq] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -0.7188\n",
      "  모델 2 R²: -8.4739\n",
      "  모델 3 R²: -11.6672\n",
      "  앙상블 가중치: [0.33333333 0.33333333 0.33333333]\n",
      "  최종 R² - 훈련: 1.0000, 테스트: -10.0041\n",
      "\n",
      "[cpi_qoq] 최종 앙상블 모델 구성...\n",
      "  모델 1 R²: -0.7188\n",
      "  모델 2 R²: -0.0911\n",
      "  모델 3 R²: -0.4718\n",
      "  앙상블 가중치: [0.33333333 0.33333333 0.33333333]\n",
      "  최종 R² - 훈련: 0.9990, 테스트: -0.3696\n",
      "======================================================================\n",
      "최종 최적화된 앙상블 모델 훈련 완료\n",
      "\n",
      "최종 결과 요약:\n",
      "  - 앙상블 모델 수: 6\n",
      "  - 예측 결과 shape: (7, 6)\n",
      "  - 각 target별 3개 모델의 가중 앙상블 적용\n",
      "\n",
      "성능 미리보기:\n",
      "  leading_index: R² = -0.0901\n",
      "  term_spread: R² = 0.2840\n",
      "  credit_spread: R² = 0.5541\n",
      "  esi: R² = -1.5001\n",
      "  exchange_usd_krw_close: R² = -10.0041\n",
      "  cpi_qoq: R² = -0.3696\n",
      "======================================================================\n",
      "  모델 2 R²: -0.0911\n",
      "  모델 3 R²: -0.4718\n",
      "  앙상블 가중치: [0.33333333 0.33333333 0.33333333]\n",
      "  최종 R² - 훈련: 0.9990, 테스트: -0.3696\n",
      "======================================================================\n",
      "최종 최적화된 앙상블 모델 훈련 완료\n",
      "\n",
      "최종 결과 요약:\n",
      "  - 앙상블 모델 수: 6\n",
      "  - 예측 결과 shape: (7, 6)\n",
      "  - 각 target별 3개 모델의 가중 앙상블 적용\n",
      "\n",
      "성능 미리보기:\n",
      "  leading_index: R² = -0.0901\n",
      "  term_spread: R² = 0.2840\n",
      "  credit_spread: R² = 0.5541\n",
      "  esi: R² = -1.5001\n",
      "  exchange_usd_krw_close: R² = -10.0041\n",
      "  cpi_qoq: R² = -0.3696\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 최적화된 파라미터로 앙상블 모델 훈련\n",
    "def train_final_optimized_models(X_train, y_train, X_test, y_test, optimized_params_dict, target_columns):\n",
    "    \"\"\"\n",
    "    최적화된 파라미터로 최종 앙상블 모델 훈련\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "    \n",
    "    models = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    print(\"최적화된 파라미터로 최종 앙상블 모델 훈련...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for target in target_columns:\n",
    "        print(f\"\\n[{target}] 최종 앙상블 모델 구성...\")\n",
    "        \n",
    "        # 최적 파라미터 가져오기\n",
    "        best_params = optimized_params_dict[target].copy()\n",
    "        best_params.update({\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 0\n",
    "        })\n",
    "        \n",
    "        # 3개의 다양한 앙상블 모델 생성\n",
    "        ensemble_models = []\n",
    "        ensemble_train_preds = []\n",
    "        ensemble_test_preds = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            # 각 모델에 약간의 변화 주기\n",
    "            model_params = best_params.copy()\n",
    "            model_params['random_state'] = 42 + i * 100\n",
    "            \n",
    "            if i == 1:  # 두 번째 모델: 더 보수적\n",
    "                model_params['learning_rate'] *= 0.8\n",
    "                model_params['reg_alpha'] *= 1.2\n",
    "            elif i == 2:  # 세 번째 모델: 더 공격적\n",
    "                model_params['learning_rate'] *= 1.2\n",
    "                model_params['max_depth'] = min(model_params['max_depth'] + 1, 10)\n",
    "            \n",
    "            # 모델 생성 및 훈련\n",
    "            model = XGBRegressor(**model_params)\n",
    "            \n",
    "            try:\n",
    "                from xgboost.callback import EarlyStopping\n",
    "                model.fit(\n",
    "                    X_train, y_train[target],\n",
    "                    eval_set=[(X_test, y_test[target])],\n",
    "                    callbacks=[EarlyStopping(rounds=30)],\n",
    "                    verbose=False\n",
    "                )\n",
    "            except:\n",
    "                model.fit(X_train, y_train[target])\n",
    "            \n",
    "            # 예측\n",
    "            train_pred = model.predict(X_train)\n",
    "            test_pred = model.predict(X_test)\n",
    "            \n",
    "            ensemble_models.append(model)\n",
    "            ensemble_train_preds.append(train_pred)\n",
    "            ensemble_test_preds.append(test_pred)\n",
    "            \n",
    "            # 개별 모델 성능\n",
    "            individual_r2 = sklearn_r2_score(y_test[target], test_pred)\n",
    "            print(f\"  모델 {i+1} R²: {individual_r2:.4f}\")\n",
    "        \n",
    "        # 앙상블 예측 (가중 평균 - 성능 기반)\n",
    "        weights = []\n",
    "        for i, preds in enumerate(ensemble_test_preds):\n",
    "            r2 = sklearn_r2_score(y_test[target], preds)\n",
    "            weight = max(0.1, r2)  # 최소 가중치 0.1\n",
    "            weights.append(weight)\n",
    "        \n",
    "        # 정규화\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        # 가중 평균 계산\n",
    "        final_train_pred = np.average(ensemble_train_preds, axis=0, weights=weights)\n",
    "        final_test_pred = np.average(ensemble_test_preds, axis=0, weights=weights)\n",
    "        \n",
    "        # 최종 성능\n",
    "        final_train_r2 = sklearn_r2_score(y_train[target], final_train_pred)\n",
    "        final_test_r2 = sklearn_r2_score(y_test[target], final_test_pred)\n",
    "        \n",
    "        print(f\"  앙상블 가중치: {weights}\")\n",
    "        print(f\"  최종 R² - 훈련: {final_train_r2:.4f}, 테스트: {final_test_r2:.4f}\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        models[target] = {\n",
    "            'ensemble_models': ensemble_models,\n",
    "            'weights': weights,\n",
    "            'best_params': best_params\n",
    "        }\n",
    "        \n",
    "        predictions[target] = {\n",
    "            'train_pred': final_train_pred,\n",
    "            'test_pred': final_test_pred\n",
    "        }\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"최종 최적화된 앙상블 모델 훈련 완료\")\n",
    "    \n",
    "    return models, predictions\n",
    "\n",
    "# 최종 모델 훈련 실행\n",
    "models, predictions = train_final_optimized_models(\n",
    "    X_train, y_train, X_test, y_test, optimized_params_dict, available_columns\n",
    ")\n",
    "\n",
    "# 예측 결과 통합\n",
    "y_pred_combined = np.zeros((len(X_test), len(available_columns)))\n",
    "for i, target in enumerate(available_columns):\n",
    "    y_pred_combined[:, i] = predictions[target]['test_pred']\n",
    "\n",
    "print(f\"\\n최종 결과 요약:\")\n",
    "print(f\"  - 앙상블 모델 수: {len(models)}\")\n",
    "print(f\"  - 예측 결과 shape: {y_pred_combined.shape}\")\n",
    "print(f\"  - 각 target별 3개 모델의 가중 앙상블 적용\")\n",
    "\n",
    "# 전체 성능 미리보기\n",
    "print(f\"\\n성능 미리보기:\")\n",
    "for target in available_columns:\n",
    "    from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "    r2 = sklearn_r2_score(y_test[target], predictions[target]['test_pred'])\n",
    "    print(f\"  {target}: R² = {r2:.4f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6af91386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 모델 성능 평가\n",
      "================================================================================\n",
      "지표명                  |      MSE |     RMSE |      MAE |       R²\n",
      "================================================================================\n",
      "leading_index        |   0.0619 |   0.2488 |   0.2204 |  -0.0901\n",
      "term_spread          |   0.0054 |   0.0734 |   0.0651 |   0.2840\n",
      "credit_spread        |   0.0299 |   0.1729 |   0.1511 |   0.5541\n",
      "esi                  |  13.6264 |   3.6914 |   2.9273 |  -1.5001\n",
      "exchange_usd_krw_close | 19704.5610 | 140.3729 | 133.3171 | -10.0041\n",
      "cpi_qoq              |   0.1407 |   0.3751 |   0.2967 |  -0.3696\n",
      "================================================================================\n",
      "평균                   |          |  24.1558 |  22.8296 |  -1.8543\n",
      "================================================================================\n",
      "\n",
      "평가 완료:\n",
      "  - 평가된 지표 수: 6\n",
      "  - 테스트 데이터 크기: (7, 6)\n",
      "  - 예측 결과 크기: (7, 6)\n",
      "\n",
      "R² 기준 성능 순위:\n",
      "  1. credit_spread: R² = 0.5541\n",
      "  2. term_spread: R² = 0.2840\n",
      "  3. leading_index: R² = -0.0901\n",
      "  4. cpi_qoq: R² = -0.3696\n",
      "  5. esi: R² = -1.5001\n",
      "  6. exchange_usd_krw_close: R² = -10.0041\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 모델 평가 및 성능 분석\n",
    "def evaluate_xgboost_models(y_true, y_pred, models, feature_names):\n",
    "    \"\"\"\n",
    "    XGBoost 모델들의 성능 평가\n",
    "    \"\"\"\n",
    "    # 함수 내에서 명시적 import로 변수명 충돌 방지\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score as sklearn_r2_score\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    print(\"XGBoost 모델 성능 평가\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'지표명':20} | {'MSE':>8} | {'RMSE':>8} | {'MAE':>8} | {'R²':>8}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, feature in enumerate(feature_names):\n",
    "        y_true_feature = y_true.iloc[:, i] if hasattr(y_true, 'iloc') else y_true[:, i]\n",
    "        y_pred_feature = y_pred[:, i]\n",
    "        \n",
    "        mse = mean_squared_error(y_true_feature, y_pred_feature)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true_feature, y_pred_feature)\n",
    "        r2 = sklearn_r2_score(y_true_feature, y_pred_feature)\n",
    "        \n",
    "        metrics[feature] = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2\n",
    "        }\n",
    "        \n",
    "        print(f\"{feature:20} | {mse:8.4f} | {rmse:8.4f} | {mae:8.4f} | {r2:8.4f}\")\n",
    "    \n",
    "    # 전체 평균 성능\n",
    "    avg_rmse = np.mean([metric['RMSE'] for metric in metrics.values()])\n",
    "    avg_mae = np.mean([metric['MAE'] for metric in metrics.values()])\n",
    "    avg_r2 = np.mean([metric['R2'] for metric in metrics.values()])\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'평균':20} | {'':8} | {avg_rmse:8.4f} | {avg_mae:8.4f} | {avg_r2:8.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 모델 평가 실행\n",
    "metrics = evaluate_xgboost_models(y_test, y_pred_combined, models, available_columns)\n",
    "\n",
    "print(f\"\\n평가 완료:\")\n",
    "print(f\"  - 평가된 지표 수: {len(metrics)}\")\n",
    "print(f\"  - 테스트 데이터 크기: {y_test.shape}\")\n",
    "print(f\"  - 예측 결과 크기: {y_pred_combined.shape}\")\n",
    "\n",
    "# 모델별 성능 순위\n",
    "performance_ranking = sorted(metrics.items(), key=lambda x: x[1]['R2'], reverse=True)\n",
    "print(f\"\\nR² 기준 성능 순위:\")\n",
    "for i, (feature, metric) in enumerate(performance_ranking, 1):\n",
    "    print(f\"  {i}. {feature}: R² = {metric['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7863594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Feature Importance 분석\n",
      "============================================================\n",
      "상위 10개 주요 Feature:\n",
      " 1. term_spread_ma_4                   : 0.0991\n",
      " 2. esi_ma_4                           : 0.0773\n",
      " 3. exchange_usd_krw_close_ma_4        : 0.0735\n",
      " 4. cpi_qoq_ma_4                       : 0.0704\n",
      " 5. credit_spread_lag_1                : 0.0624\n",
      " 6. esi_lag_2                          : 0.0591\n",
      " 7. leading_index_qoq                  : 0.0540\n",
      " 8. term_spread_lag_1                  : 0.0518\n",
      " 9. esi_lag_1                          : 0.0477\n",
      "10. term_spread_qoq                    : 0.0443\n",
      "\n",
      "지표별 Top 3 Features:\n",
      "============================================================\n",
      "\n",
      "leading_index:\n",
      "  term_spread_ma_4              : 0.3481\n",
      "  leading_index_lag_1           : 0.0911\n",
      "  leading_index_ma_4            : 0.0737\n",
      "\n",
      "term_spread:\n",
      "  term_spread_ma_4              : 0.1537\n",
      "  leading_index_qoq             : 0.0927\n",
      "  esi_ma_4                      : 0.0895\n",
      "\n",
      "credit_spread:\n",
      "  esi_lag_2                     : 0.1713\n",
      "  leading_index_qoq             : 0.1311\n",
      "  credit_spread_lag_1           : 0.1244\n",
      "\n",
      "esi:\n",
      "  esi_ma_4                      : 0.1627\n",
      "  leading_index_lag_1           : 0.1021\n",
      "  leading_index_lag_2           : 0.0998\n",
      "\n",
      "exchange_usd_krw_close:\n",
      "  exchange_usd_krw_close_ma_4   : 0.2781\n",
      "  exchange_usd_krw_close_lag_1  : 0.1167\n",
      "  credit_spread_lag_1           : 0.1136\n",
      "\n",
      "cpi_qoq:\n",
      "  cpi_qoq_lag_2                 : 0.1256\n",
      "  leading_index_lag_2           : 0.0815\n",
      "  cpi_qoq_ma_4                  : 0.0756\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Feature Importance 분석 (간결화)\n",
    "def analyze_feature_importance(models, feature_names, top_n=10):\n",
    "    \"\"\"\n",
    "    XGBoost 모델들의 Feature Importance 분석 (시각화 최소화)\n",
    "    \"\"\"\n",
    "    print(\"XGBoost Feature Importance 분석\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 전체 Feature importance 평균 계산\n",
    "    all_importance = {}\n",
    "    for feature, model in models.items():\n",
    "        importance = model.feature_importances_\n",
    "        for i, feat in enumerate(X_train.columns):\n",
    "            if feat not in all_importance:\n",
    "                all_importance[feat] = []\n",
    "            all_importance[feat].append(importance[i])\n",
    "    \n",
    "    # 평균 중요도 계산\n",
    "    avg_importance = {feat: np.mean(scores) for feat, scores in all_importance.items()}\n",
    "    top_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    print(f\"상위 {top_n}개 주요 Feature:\")\n",
    "    for i, (feat, importance) in enumerate(top_features, 1):\n",
    "        print(f\"{i:2}. {feat:35}: {importance:.4f}\")\n",
    "    \n",
    "    # 지표별 top 3 features 요약\n",
    "    feature_importance_summary = {}\n",
    "    print(f\"\\n지표별 Top 3 Features:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for feature, model in models.items():\n",
    "        importance = model.feature_importances_\n",
    "        feature_df = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False).head(3)\n",
    "        \n",
    "        feature_importance_summary[feature] = feature_df['feature'].tolist()\n",
    "        print(f\"\\n{feature}:\")\n",
    "        for i, row in feature_df.iterrows():\n",
    "            print(f\"  {row['feature']:30}: {row['importance']:.4f}\")\n",
    "    \n",
    "    return feature_importance_summary\n",
    "\n",
    "# Feature importance 분석 실행\n",
    "feature_importance_summary = analyze_feature_importance(models, available_columns)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e2214c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 Q3 XGBoost 예측 및 결과 정리\n",
      "======================================================================\n",
      "1. 2025 Q3 예측 실행...\n",
      "\n",
      "2025년 Q3 경제지표 예측 결과:\n",
      "======================================================================\n",
      "지표명                       |          예측값 |        신뢰도\n",
      "======================================================================\n",
      "경기선행지수                    |     100.119 |         낮음\n",
      "장단기금리차                    |       0.268 |         낮음\n",
      "신용스프레드                    |       6.183 |         낮음\n",
      "경제심리지수                    |      88.778 |         낮음\n",
      "원달러환율                     |    1273.561 |         낮음\n",
      "분기물가상승률                   |       0.578 |         낮음\n",
      "\n",
      "2025 Q2 대비 Q3 변화율:\n",
      "============================================================\n",
      "지표명                       |      Q2→Q3 |       전망\n",
      "============================================================\n",
      "경기선행지수                    |      -0.7% |       하락\n",
      "장단기금리차                    |     -22.8% |       하락\n",
      "신용스프레드                    |      +7.3% |       상승\n",
      "경제심리지수                    |      -2.3% |       하락\n",
      "원달러환율                     |      -9.0% |       하락\n",
      "분기물가상승률                   |    +128.7% |       상승\n",
      "============================================================\n",
      "상승 예상: 2개, 하락 예상: 4개\n",
      "\n",
      "모델 성능 요약:\n",
      "==================================================\n",
      "평균 R² 점수: -2.379\n",
      "평균 RMSE: 18.718\n",
      "사용 Feature 수: 24\n",
      "훈련 데이터: 30개 분기\n",
      "\n",
      "결과 파일 저장...\n",
      "결과 파일 저장 완료:\n",
      "  - xgboost_model_performance.csv\n",
      "  - 2025_Q3_xgboost_predictions.csv\n",
      "\n",
      "======================================================================\n",
      "XGBoost 2025년 Q3 ECOS 지표 예측 분석 완료\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 2025 Q3 예측 및 최종 결과 정리\n",
    "def complete_prediction_analysis(models, X_scaled, data, available_columns, metrics):\n",
    "    \"\"\"\n",
    "    2025 Q3 예측 실행 및 최종 결과 정리 (통합 버전)\n",
    "    \"\"\"\n",
    "    print(\"2025 Q3 XGBoost 예측 및 결과 정리\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 1. 2025 Q3 예측 실행\n",
    "    last_features = X_scaled.iloc[-1].values\n",
    "    future_predictions = {}\n",
    "    \n",
    "    print(\"1. 2025 Q3 예측 실행...\")\n",
    "    for target in available_columns:\n",
    "        model = models[target]\n",
    "        pred = model.predict(last_features.reshape(1, -1))[0]\n",
    "        future_predictions[target] = pred\n",
    "    \n",
    "    # 2. 지표 한글명 매핑\n",
    "    interpretation = {\n",
    "        'leading_index': '경기선행지수',\n",
    "        'term_spread': '장단기금리차', \n",
    "        'credit_spread': '신용스프레드',\n",
    "        'esi': '경제심리지수',\n",
    "        'exchange_usd_krw_close': '원달러환율',\n",
    "        'cpi_qoq': '분기물가상승률'\n",
    "    }\n",
    "    \n",
    "    # 3. 예측 결과 출력\n",
    "    print(f\"\\n2025년 Q3 경제지표 예측 결과:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'지표명':25} | {'예측값':>12} | {'신뢰도':>10}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for feature in available_columns:\n",
    "        value = future_predictions[feature]\n",
    "        r2 = metrics[feature]['R2']\n",
    "        confidence = \"높음\" if r2 > 0.7 else \"보통\" if r2 > 0.5 else \"낮음\"\n",
    "        korean_name = interpretation.get(feature, feature)\n",
    "        print(f\"{korean_name:25} | {value:11.3f} | {confidence:>10}\")\n",
    "    \n",
    "    # 4. 변화율 분석\n",
    "    print(f\"\\n2025 Q2 대비 Q3 변화율:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'지표명':25} | {'Q2→Q3':>10} | {'전망':>8}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    trend_summary = {'상승': 0, '하락': 0}\n",
    "    if len(data) > 0:\n",
    "        last_actual = data.iloc[-1]\n",
    "        for feature in available_columns:\n",
    "            if feature in last_actual.index:\n",
    "                q2_value = last_actual[feature]\n",
    "                q3_value = future_predictions[feature]\n",
    "                change_rate = ((q3_value - q2_value) / q2_value) * 100\n",
    "                trend = \"상승\" if change_rate > 0 else \"하락\"\n",
    "                trend_summary[trend] += 1\n",
    "                \n",
    "                korean_name = interpretation.get(feature, feature)\n",
    "                print(f\"{korean_name:25} | {change_rate:+9.1f}% | {trend:>8}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"상승 예상: {trend_summary['상승']}개, 하락 예상: {trend_summary['하락']}개\")\n",
    "    \n",
    "    # 5. 성능 요약\n",
    "    print(f\"\\n모델 성능 요약:\")\n",
    "    print(\"=\" * 50)\n",
    "    avg_r2 = np.mean([metrics[f]['R2'] for f in available_columns])\n",
    "    avg_rmse = np.mean([metrics[f]['RMSE'] for f in available_columns])\n",
    "    print(f\"평균 R² 점수: {avg_r2:.3f}\")\n",
    "    print(f\"평균 RMSE: {avg_rmse:.3f}\")\n",
    "    print(f\"사용 Feature 수: {X_scaled.shape[1]}\")\n",
    "    print(f\"훈련 데이터: {len(X_train)}개 분기\")\n",
    "    \n",
    "    return future_predictions, trend_summary\n",
    "\n",
    "# 통합 분석 실행\n",
    "future_predictions, trend_summary = complete_prediction_analysis(\n",
    "    models, X_scaled, data, available_columns, metrics\n",
    ")\n",
    "\n",
    "# 6. 결과 파일 저장\n",
    "print(f\"\\n결과 파일 저장...\")\n",
    "try:\n",
    "    # 성능 결과\n",
    "    performance_data = []\n",
    "    for feature, metric in metrics.items():\n",
    "        performance_data.append({\n",
    "            'Feature': feature,\n",
    "            'RMSE': metric['RMSE'],\n",
    "            'MAE': metric['MAE'],\n",
    "            'R2': metric['R2'],\n",
    "            'Model_Type': 'XGBoost_Optimized'\n",
    "        })\n",
    "    performance_df = pd.DataFrame(performance_data).sort_values('R2', ascending=False)\n",
    "    performance_df.to_csv('xgboost_model_performance.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 예측 결과\n",
    "    interpretation = {\n",
    "        'leading_index': '경기선행지수', 'term_spread': '장단기금리차', \n",
    "        'credit_spread': '신용스프레드', 'esi': '경제심리지수',\n",
    "        'exchange_usd_krw_close': '원달러환율', 'cpi_qoq': '분기물가상승률'\n",
    "    }\n",
    "    \n",
    "    future_data = []\n",
    "    for feature in available_columns:\n",
    "        korean_name = interpretation.get(feature, feature)\n",
    "        value = future_predictions[feature]\n",
    "        r2_score = metrics[feature]['R2']\n",
    "        confidence = \"높음\" if r2_score > 0.7 else \"보통\" if r2_score > 0.5 else \"낮음\"\n",
    "        \n",
    "        future_data.append({\n",
    "            '지표코드': feature,\n",
    "            '지표명': korean_name,\n",
    "            '2025_Q3_예측값': round(value, 4),\n",
    "            'R2_Score': round(r2_score, 4),\n",
    "            '신뢰도': confidence\n",
    "        })\n",
    "    \n",
    "    future_df = pd.DataFrame(future_data)\n",
    "    future_df.to_csv('2025_Q3_xgboost_predictions.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"결과 파일 저장 완료:\")\n",
    "    print(\"  - xgboost_model_performance.csv\")\n",
    "    print(\"  - 2025_Q3_xgboost_predictions.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"결과 저장 중 오류: {e}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"XGBoost 2025년 Q3 ECOS 지표 예측 분석 완료\")\n",
    "print(f\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
